pub mod chain;
pub mod sequential;

use std::collections::HashMap;

use serde::Serialize;

use crate::{
    llm::{error::LLMError, LLMResponse},
    record::Record,
};

#[async_trait::async_trait(?Send)]
pub trait Chain {
    /// Execute an LLM chain.
    async fn execute(&mut self) -> Result<ChainResult, LLMError>;

    /// Set the context of the LLMChain.
    fn load_context<T>(&mut self, context: &T)
    where
        T: Serialize,
    {
        let context = serde_json::to_value(context).unwrap();
        let context = context.as_object().unwrap();
        for (key, value) in context {
            self.context().insert(key.to_string(), value.to_string());
        }
    }

    /// Save a record content to the context of an LLM Chain.
    fn load_record(&mut self, name: &str, record: Record) {
        if !self.context().contains_key(name) {
            self.context().insert(name.to_string(), record.content.to_string());
        }
    }

    /// Get the context of the LLMChain.
    fn context(&mut self) -> &mut HashMap<String, String>;
}

pub struct ChainResult {
    /// Name of the chain which generated the result.
    pub name: String,

    /// LLM response generated by the chain.
    llm_response: Option<LLMResponse>,
}

impl ChainResult {
    /// Create a new chain result.
    pub fn new(name: String) -> ChainResult {
        ChainResult {
            name,
            llm_response: None,
        }
    }

    /// Get the LLM response content generated by the chain.
    pub fn content(&self) -> String {
        self.llm_response.as_ref().unwrap_or(&LLMResponse::Empty).get_response_content()
    }

    /// Get the role of the LLM response generated by the chain.
    pub fn role(&self) -> String {
        self.llm_response.as_ref().unwrap_or(&LLMResponse::Empty).get_role()
    }

    /// Get the LLM response generated by the chain.
    pub fn with_llm_response(mut self, llm_response: LLMResponse) -> Self {
        self.llm_response = Some(llm_response);
        self
    }
}
